{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "148cca55",
   "metadata": {},
   "source": [
    "## Image Classifier\n",
    "\n",
    "The objective is to build an image classifier that is capable of properly identifying four different categories of image. \n",
    "\n",
    "The data consists of various train and test samples across the four categories of image. The data for a specific category is a singular image that has been flipped, rotated, or slightly altered in some way. \n",
    "\n",
    "### Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d75438e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f35778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78514032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9a9e6",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "#### a) Use the \"ImageDataGenerator()\" class from keras.processing.image to build out an instance called \"train_datagen\" with the following parameters: \n",
    "\n",
    "rescale = 1./255\n",
    "\n",
    "shear_range = 0.2\n",
    "\n",
    "zoom_range = 0.2\n",
    "\n",
    "horizontal_flip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce9e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f532318",
   "metadata": {},
   "source": [
    "#### b) Then build training set by using the method \".flow_from_directory()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d337b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(\n",
    "    'ass6_dataset_train', # replace with the path where your training data is stored\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb7da4b1",
   "metadata": {},
   "source": [
    "#### c) Observations:\n",
    "\n",
    "The image shapes include arc, mailbox, cross, and complex structure. Images are all black and white. There are 4 classes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156c9ff",
   "metadata": {},
   "source": [
    "## 2. Initial Classifier Build: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c7e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64,64,3), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(units= 4 , # of classes\n",
    "                     activation='softmax'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59c4fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,668\n",
      "Trainable params: 1,625,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6d7f6",
   "metadata": {},
   "source": [
    "## 3. Model Runs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf2cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 1.4101 - accuracy: 0.3182\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 1.0660 - accuracy: 0.5682\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.4886 - accuracy: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c89d16730>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_set,\n",
    "               steps_per_epoch=3,\n",
    "               epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2338e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('classifier_ass6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34c98eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "ass6_dataset_test/C033.png\n",
      "ass6_dataset_test/1022.png\n",
      "ass6_dataset_test/4011.png\n",
      "ass6_dataset_test/1053.png\n",
      "ass6_dataset_test/6051.png\n",
      "ass6_dataset_test/4053.png\n",
      "ass6_dataset_test/C014.png\n",
      "ass6_dataset_test/6023.png\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('classifier_ass6.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# test data path\n",
    "img_dir = \"ass6_dataset_test\" # Enter Directory of test set\n",
    "\n",
    "# iterate over each test image\n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "\n",
    "# print the files in the dataset_test folder \n",
    "for f in files:\n",
    "    print(f)\n",
    "    \n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d7db96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category 1': 0, 'category 2': 1, 'category 3': 2, 'category 4': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check category labels in training_set\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01581eb5",
   "metadata": {},
   "source": [
    "#### identify what category each images in test daset belongs to using images in the training set as references:\n",
    "\n",
    "image 1022，1053 : 0\n",
    "\n",
    "image 4011，4053: 2\n",
    "\n",
    "image 6023, 6051: 1\n",
    "\n",
    "image C014, C033: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bbd36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label= [3, 0, 2, 0, 1, 2, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1647d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test_label, results)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33355c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.3615 - accuracy: 0.2812\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 1.4229 - accuracy: 0.2812\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.0058 - accuracy: 0.1667\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.3998 - accuracy: 0.3125\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7987 - accuracy: 0.1250\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.0513 - accuracy: 0.5417\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.4325 - accuracy: 0.2812\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2955 - accuracy: 0.1250\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.9825 - accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0526 - accuracy: 0.6250\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8064 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7866 - accuracy: 0.7500\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6039 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5816 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.4463 - accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7442 - accuracy: 0.3125\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4524 - accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0353 - accuracy: 0.4583\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8660 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8658 - accuracy: 0.8438\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6751 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6865 - accuracy: 0.8125\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4550 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3334 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.4442 - accuracy: 0.0625\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4762 - accuracy: 0.2812\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.2502 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4490 - accuracy: 0.4062\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4430 - accuracy: 0.4688\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0481 - accuracy: 0.6250\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6447 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5620 - accuracy: 0.8750\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7538 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5135 - accuracy: 0.8125\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4296 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3320 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.3707 - accuracy: 0.3750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1174 - accuracy: 0.2188\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.6237 - accuracy: 0.3333\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3577 - accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2307 - accuracy: 0.3125\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9988 - accuracy: 0.7083\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8370 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7540 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7318 - accuracy: 0.8333\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5543 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4623 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3192 - accuracy: 0.9583\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2156 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2126 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3635 - accuracy: 0.9167\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1812 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1246 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3797 - accuracy: 0.8750\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0968 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1653 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2362 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.3988 - accuracy: 0.2812\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4751 - accuracy: 0.2188\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.1733 - accuracy: 0.3750\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8820 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8327 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5792 - accuracy: 0.9583\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3420 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2809 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4041 - accuracy: 0.8750\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1621 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1688 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2244 - accuracy: 0.9167\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2321 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1754 - accuracy: 0.9583\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1523 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1823 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0964 - accuracy: 0.9583\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1467 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2014 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 7\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1267 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0941 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.3922 - accuracy: 0.2812\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0103 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.4810 - accuracy: 0.4167\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0067 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4122 - accuracy: 0.5938\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2176 - accuracy: 0.5417\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8346 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6545 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6494 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6334 - accuracy: 0.8750\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5710 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2415 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# tuples with steps_per_epoch and epochs \n",
    "combinations = [(1,1), (1,2), (1,3), (2,4), (2,5), (2,6), (3,7), (3,8), (5,9), (5,10)]\n",
    "\n",
    "test_label= [3, 0, 2, 0, 1, 2, 3, 1]\n",
    "\n",
    "# loop over combinations and fit model\n",
    "for step, epoch in combinations:\n",
    "    # classifier\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64,64,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units=128, activation='relu'))\n",
    "    classifier.add(Dense(units=4, activation='softmax'))\n",
    "    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #fix the warning ???\n",
    "    for e in range(epoch):\n",
    "        print(f'Epoch {e}')\n",
    "        batches = 0\n",
    "        for x, y in train_set:\n",
    "          classifier.fit(x, y)\n",
    "          batches += 1\n",
    "          if batches >= step:\n",
    "            break\n",
    "\n",
    "    # fit classifier\n",
    "    history = classifier.fit(train_set, steps_per_epoch=step, epochs=epoch, verbose=0)\n",
    "\n",
    "    # get accuracy of model\n",
    "    test_data = []\n",
    "    \n",
    "    img_dir = \"ass6_dataset_test\" # Enter Directory of test set\n",
    "    test_data_path = os.path.join(img_dir, '*g')\n",
    "    test_files = glob.glob(test_data_path)\n",
    "\n",
    "    for f1 in test_files:\n",
    "        img = image.load_img(f1, target_size=(64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        test_data.append(img)\n",
    "    test_data = np.concatenate(test_data, axis=0)\n",
    "    y_pred = classifier.predict(test_data)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(test_label, y_pred)\n",
    "   \n",
    "    # append the results to the list of results\n",
    "    results.append((step, epoch, accuracy))\n",
    "\n",
    "# create a pandas DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results, columns=['Steps_per_epoch', 'Epochs', 'Accuracy'])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cc95663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with steps_per_epoch=1 and epochs=1\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.3992 - accuracy: 0.3438\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 2.5921 - accuracy: 0.2812\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "accuracy of model: 0.25\n",
      "\n",
      "Training model with steps_per_epoch=1 and epochs=2\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.4595 - accuracy: 0.1250\n",
      "Epoch 1\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7f8caa2e2700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.1458 - accuracy: 0.4167\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.0381 - accuracy: 0.5938\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.0368 - accuracy: 0.4375\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "accuracy of model: 0.5\n",
      "\n",
      "Training model with steps_per_epoch=1 and epochs=3\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.3881 - accuracy: 0.2812\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4404 - accuracy: 0.2812\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.6823 - accuracy: 0.3333\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.0849 - accuracy: 0.5625\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.0113 - accuracy: 0.6562\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.9318 - accuracy: 0.6875\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=2 and epochs=4\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.4239 - accuracy: 0.1875\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2804 - accuracy: 0.2812\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.1459 - accuracy: 0.5417\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1642 - accuracy: 0.5938\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9303 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0199 - accuracy: 0.6667\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8040 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8305 - accuracy: 0.8125\n",
      "Epoch 1/4\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.5519 - accuracy: 0.8594\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.3667 - accuracy: 0.9286\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.2471 - accuracy: 0.9464\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.1703 - accuracy: 0.9464\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=2 and epochs=5\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.3741 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.5406 - accuracy: 0.2812\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2243 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3728 - accuracy: 0.1667\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1214 - accuracy: 0.5312\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0707 - accuracy: 0.6875\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9983 - accuracy: 0.7083\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9307 - accuracy: 0.7188\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8793 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6356 - accuracy: 0.9167\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.5533 - accuracy: 0.9107\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.3932 - accuracy: 0.9107\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.2630 - accuracy: 0.9643\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1934 - accuracy: 0.9464\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.2343 - accuracy: 0.9286\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=2 and epochs=6\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.3936 - accuracy: 0.2812\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7221 - accuracy: 0.2188\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4796 - accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1145 - accuracy: 0.7188\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1035 - accuracy: 0.5312\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0927 - accuracy: 0.5417\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0753 - accuracy: 0.5312\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8455 - accuracy: 0.6562\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6582 - accuracy: 0.7917\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6433 - accuracy: 0.8750\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5228 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5210 - accuracy: 0.9167\n",
      "Epoch 1/6\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.3996 - accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.3226 - accuracy: 0.9286\n",
      "Epoch 3/6\n",
      "2/2 [==============================] - 1s 208ms/step - loss: 0.1725 - accuracy: 0.9821\n",
      "Epoch 4/6\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.1783 - accuracy: 0.9643\n",
      "Epoch 5/6\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.1226 - accuracy: 0.9821\n",
      "Epoch 6/6\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.1088 - accuracy: 0.9464\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "accuracy of model: 0.875\n",
      "\n",
      "Training model with steps_per_epoch=3 and epochs=7\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.3908 - accuracy: 0.3125\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8641 - accuracy: 0.3750\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.7561 - accuracy: 0.2500\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9831 - accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9063 - accuracy: 0.5938\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7275 - accuracy: 0.8333\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4993 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6519 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4474 - accuracy: 0.9167\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3931 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2737 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2365 - accuracy: 0.9583\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1788 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1717 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1699 - accuracy: 0.9583\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1021 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3525 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1023 - accuracy: 0.9583\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1082 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1099 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3459 - accuracy: 0.8750\n",
      "Epoch 1/7\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.2147 - accuracy: 0.9318\n",
      "Epoch 2/7\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.1172 - accuracy: 0.9545\n",
      "Epoch 3/7\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.0906 - accuracy: 0.9659\n",
      "Epoch 4/7\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.1155 - accuracy: 0.9659\n",
      "Epoch 5/7\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.0764 - accuracy: 0.9886\n",
      "Epoch 6/7\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 0.0610 - accuracy: 0.9773\n",
      "Epoch 7/7\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.0436 - accuracy: 0.9659\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=3 and epochs=8\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.4667 - accuracy: 0.0625\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.3130 - accuracy: 0.1875\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.9937 - accuracy: 0.2083\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.7390 - accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4805 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2670 - accuracy: 0.3333\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1233 - accuracy: 0.6562\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9506 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9655 - accuracy: 0.7083\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8590 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7034 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5877 - accuracy: 0.9583\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4684 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5196 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2789 - accuracy: 0.9583\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2316 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2787 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3691 - accuracy: 0.9583\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1707 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3353 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0762 - accuracy: 0.9583\n",
      "Epoch 7\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2736 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1420 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1371 - accuracy: 0.9583\n",
      "Epoch 1/8\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 0.1174 - accuracy: 0.9659\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 0.1307 - accuracy: 0.9545\n",
      "Epoch 3/8\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 0.1005 - accuracy: 0.9773\n",
      "Epoch 4/8\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1034 - accuracy: 0.9659\n",
      "Epoch 5/8\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 0.0807 - accuracy: 0.9659\n",
      "Epoch 6/8\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0406 - accuracy: 0.9886\n",
      "Epoch 7/8\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 0.0727 - accuracy: 0.9773\n",
      "Epoch 8/8\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=5 and epochs=9\n",
      "Epoch 0\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 1.4397 - accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.4268 - accuracy: 0.2188\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1533 - accuracy: 0.5833\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0099 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6524 - accuracy: 0.4062\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8776 - accuracy: 0.7917\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7650 - accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6357 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5979 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5141 - accuracy: 0.9062\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4766 - accuracy: 0.8438\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2411 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1494 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3712 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1897 - accuracy: 0.9167\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1825 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2912 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1025 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1156 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2189 - accuracy: 0.9375\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1863 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1141 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0479 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3583 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1628 - accuracy: 0.9688\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1503 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1002 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2946 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0719 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2520 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1847 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 7\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1642 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1261 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 8\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1984 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0601 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0693 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 1/9\n",
      "3/5 [=================>............] - ETA: 0s - loss: 0.0278 - accuracy: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 45 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "accuracy of model: 0.75\n",
      "\n",
      "Training model with steps_per_epoch=5 and epochs=10\n",
      "Epoch 0\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.4444 - accuracy: 0.1875\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0655 - accuracy: 0.3125\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.7491 - accuracy: 0.2917\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2541 - accuracy: 0.5312\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0847 - accuracy: 0.6562\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9424 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8215 - accuracy: 0.6562\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7667 - accuracy: 0.8125\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7392 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4640 - accuracy: 0.9688\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3824 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6634 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3926 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2288 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2166 - accuracy: 0.9583\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1564 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4243 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0674 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2451 - accuracy: 0.9062\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2439 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0520 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2147 - accuracy: 0.9062\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2193 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1251 - accuracy: 0.9688\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1896 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0674 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1713 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0907 - accuracy: 1.0000\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0621 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1180 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0669 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1093 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0494 - accuracy: 1.0000\n",
      "Epoch 7\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2418 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1060 - accuracy: 0.9375\n",
      "Epoch 8\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0382 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0897 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0271 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 9\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0549 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0634 - accuracy: 0.9688\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "3/5 [=================>............] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "accuracy of model: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# solution from isa. (warning as well...)\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results = []\n",
    "steps_ = []\n",
    "epochs_ = []\n",
    "accuracy_ = []\n",
    "\n",
    "# tuples with steps_per_epoch and epochs \n",
    "combinations = [(1,1), (1,2), (1,3), (2,4), (2,5), (2,6), (3,7), (3,8), (5,9), (5,10)]\n",
    "\n",
    "test_label= [3, 0, 2, 0, 1, 2, 3, 1]\n",
    "\n",
    "# loop over combinations and fit model\n",
    "for i in combinations:\n",
    "    # classifier\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64,64,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units=128, activation='relu'))\n",
    "    classifier.add(Dense(units=4, activation='softmax'))\n",
    "    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "            \n",
    "    step, epoch = i\n",
    "    steps_.append(step)\n",
    "    epochs_.append(epoch)\n",
    "    print(f\"Training model with steps_per_epoch={step} and epochs={epoch}\")\n",
    "    \n",
    "    #fix the warning ???\n",
    "    for e in range(epoch):\n",
    "        print(f'Epoch {e}')\n",
    "        batches = 0\n",
    "        for x, y in train_set:\n",
    "          classifier.fit(x, y)\n",
    "          batches += 1\n",
    "          if batches >= step:\n",
    "            break\n",
    "\n",
    "    # fit classifier and save model\n",
    "    classifier.fit(train_set, steps_per_epoch=step, epochs=epoch)\n",
    "    classifier.save(f'model_{step}_{epoch}.h5')\n",
    "    print(\"Saved model\")\n",
    "\n",
    "    # run model\n",
    "    model = load_model(f'model_{step}_{epoch}.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    img_dir = \"ass6_dataset_test\" # Enter Directory of test set\n",
    "    test_data_path = os.path.join(img_dir, '*g')\n",
    "    test_files = glob.glob(test_data_path)\n",
    "    \n",
    "    test_data = []\n",
    "    results = []\n",
    "    for f1 in test_files:\n",
    "        img = image.load_img(f1, target_size=(64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        test_data.append(img)\n",
    "        result = model.predict(img)\n",
    "        r = np.argmax(result, axis=1)\n",
    "        results.append(r)\n",
    "    \n",
    "    #get accuracy \n",
    "    accuracy = accuracy_score(test_label, results)\n",
    "    accuracy_.append(accuracy)\n",
    "    print(f'accuracy of model: {accuracy}\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c559d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps_per_Epoch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Steps_per_Epoch  Epochs  Accuracy\n",
       "0                1       1     0.250\n",
       "1                1       2     0.500\n",
       "2                1       3     0.750\n",
       "3                2       4     0.750\n",
       "4                2       5     0.750\n",
       "5                2       6     0.875\n",
       "6                3       7     0.750\n",
       "7                3       8     0.750\n",
       "8                5       9     0.750\n",
       "9                5      10     0.750"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'Steps_per_Epoch': steps_, 'Epochs': epochs_, 'Accuracy': accuracy_})\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d692379b",
   "metadata": {},
   "source": [
    "### Discussions:\n",
    "\n",
    "### 1. Effects of the following on accuracy and loss (train & test): \n",
    "\n",
    "#### Increasing the steps_per_epoch:\n",
    "\n",
    "1) This will help improve accuracy as the model is exposed to more batches of data, which means more frequent updates on the weight and adjusting to the training data more effectively. It leads to better generalization of the model and better accuracy on both training and test data. Also, increasing the steps_per_epoch can help to reduce overfitting, as the model is being trained on more diverse data.\n",
    "\n",
    "2) However, it can slow down training process, because model is being trained on more data. Also, it can increase the risk of overfitting, especially if the data is not diverse enough. Finally, it can increase the risk of the model overfitting to the training data if the number of epochs is not increased correspondingly. In such cases, the model may perform well on the training data, but poorly on the test data.\n",
    "\n",
    "#### Increasing the number of epochs:\n",
    "\n",
    "This usually leads to an improvement in accuracy, especially in the initial epochs. Because the network has more chances to learn the patterns in the training data, and to adjust the weights and biases to better fit the data. As the number of epochs increases, the loss on the training set generally decreases. But, the model may begin to overfit the training data, which can result in a decrease in accuracy on the test set, and an increase in the loss.\n",
    "\n",
    "\n",
    "#### 2. Two uses of zero padding in CNN:\n",
    "\n",
    "1) Keeping spatial dimensions of the input volume. This is important because convolutional layers can cause the spatial dimensions to shrink. By adding padding, we can control the output size of the convolutional layer and avoid losing spatial information.\n",
    "\n",
    "2) Ensure that the convolution operation is performed over the entire input volume, including the boundary pixels. This is important because otherwise, the filter would not be able to process the pixels at the boundary of the input volume, resulting in a loss of information.\n",
    "\n",
    "\n",
    "#### 3. use of a 1 x 1 kernel in CNN:\n",
    "\n",
    "1) dimensionality reduction or feature transformation: It acts as a filter that performs a dot product between the input and the weight matrix, producing an output that is the sum of the weighted values. The 1x1 kernel is a convolutional filter with a width and height of 1, and it can be applied to a single channel or multiple channels in the input data.When a 1x1 convolution is applied to the output of a preceding layer in a CNN, it can change the number of filters (or channels) in the output. This is useful for reducing the number of feature maps in the output of a layer, and thus, reducing the computational cost of the CNN. It can also be used for mixing features from different channels, as the convolutional operation is performed across channels as well as spatial dimensions.\n",
    "\n",
    "2) Another use is to create \"bottleneck\" layers in a CNN architecture, which improves computational efficiency and reduces # parameters required in the network. This approach involves using a 1x1 convolution to reduce the dimensionality of the input data before applying larger convolutions, which can reduce the number of computations required and make the network more efficient.\n",
    "\n",
    "\n",
    "#### 4. Advantages of a CNN over a fully connected DNN for this image classification problem:\n",
    "\n",
    "1) Higher Parameter Efficiency: CNN has smaller # parameters compared to fully connected DNN. In CNNs, the same filter is applied to different parts of the image, which makes the model more parameter efficient.\n",
    "\n",
    "2) Local Connectivity: In CNN, each neuron is connected only to a small region of the input, which makes the network more efficient at processing high dimensional inputs like images.\n",
    "\n",
    "3) Translation Invariance: CNNs can detect same features in different parts of the image. This is achieved by using filters that slide across the entire image. This helps to create a model that is invariant to translation in the input.\n",
    "\n",
    "4) Regularization: CNN uses dropout and batch normalization techniques to prevent overfitting on the training data.\n",
    "\n",
    "5) Hierarchical Learning: CNN can learn hierarchical representations of the input. The first layer of the CNN learns simple patterns like edges, lines and corners, and the subsequent layers learn more complex features like curves, shapes and textures. This makes the CNN better at recognizing complex objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928df4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0aad21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
